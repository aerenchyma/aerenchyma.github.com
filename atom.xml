<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[everything's interesting]]></title>
  <link href="http://aerenchyma.github.com/atom.xml" rel="self"/>
  <link href="http://aerenchyma.github.com/"/>
  <updated>2013-04-16T13:18:42-04:00</updated>
  <id>http://aerenchyma.github.com/</id>
  <author>
    <name><![CDATA[Jackie Cohen]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A useful Ruby script (part I)]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/04/15/a-useful-ruby-script-for-mapping-projects/"/>
    <updated>2013-04-15T11:46:00-04:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/04/15/a-useful-ruby-script-for-mapping-projects</id>
    <content type="html"><![CDATA[<h2>once upon a time</h2>

<p>in late 2012, I was at a bar with some friends, but the night ended with some excitement.</p>

<p>Soon after I left, I began writing a script in order to put together .csv files of locations, names, and phone numbers of various types of sites within a certain radius! The exclamation point there is a little facetious, but I&#8217;m not kidding about the excitement. I love information retrieval and teaching programming for use to improve efficiency. I like scripting and any chance to share how cool it is; this was all of the above.</p>

<p>This is a project that&#8217;s taken place in several parts, and due to various pending Terms-of-Service (TOS) agreements and new <a href="http://en.wikipedia.org/wiki/Api">API</a> developments, I won&#8217;t be publishing the final version of the code online <em>yet.</em> But I&#8217;m outlining this process here anyhow because I think writing about code is good.</p>

<p><a href="http://aerenchyma.github.io/blog/2013/04/15/a-useful-ruby-script-for-mapping-projects/">Part I</a> (this post) will address the basic technical architecture of writing a Ruby script to speed up data-gathering for a local non-profit organization, use of particular Ruby gems, etc (and the initial questions that led to the script writing).</p>

<p><a href="">Part II</a> (to come) will address the whys &#8211; specifically, why Ruby worked well for this project and what I found to be useful takeaways from it. I am especially interested in takeaways with respect to teaching programming, ways of looking at projects as a developer, and application of technical skills as a service.</p>

<p><a href="">Part III</a> (to come) will address further technical possibilities &#8211; what should work better, what tools are future possibilities, what questions this generated, and a clear outline of what I&#8217;ve learnt (from a programming perspective) by working on this.</p>

<!-- more -->


<h2>initiation</h2>

<p>&#8220;Is there a faster way?&#8221; my friend asked, wondering if there were a way to automate some data gathering her organization was doing. <em>Is there a faster way?</em>  The answer is usually yes.</p>

<p>My friend and the organization she worked for wanted a faster way to gather data for a mapping project: for example, amidst this project, they might want to gather .csv files that held lists of places of worship (e.g. churches, mosques, temples&#8230;), within the tri-county area of Southeastern Michigan. They would analyze and separate these data in various ways and upload the final files for a given search to <a href="http://www.arcgis.com/about/">ArcGIS</a>, in order to create maps.</p>

<p>The problems?</p>

<ol>
<li><p><strong>Getting the data was hard:</strong>
In some cases for mapping sites of given types or categories, the data was readily available. The governent provides data files, including GIS shape files, with a lot of publicly available information; beyond things like that, there are available lists from many public sources; lists of public schools and locations, for example. But it&#8217;s hard to find a list of all <em>places of worship</em>, say, because though this may be one category at a given level, on an organizational level these belong to many different categories: churches of a given denomination and Sikh Temples are usually not listed in the same public dataset, especially not throughout the tri-county area.</p></li>
<li><p><strong>Getting the data was slow:</strong>
The way they were currently approaching these problems, she explained, was making educated searches for terms (e.g. places of worship) that weren&#8217;t easily correlated in your average public database and which didn&#8217;t have an overarching organization. When the resulting data wasn&#8217;t available in a database or google spreadsheet form, they copied them into Excel and spot-checked them for accuracy, going back and searching. They were working on a lot of projects simultaneously and this process was turning into quite a timesink for some.</p></li>
</ol>


<p>Was there a faster way? <em>Yes</em>, I said.</p>

<p>There are many services, both specific to the state of Michigan or metro Detroit and nationally or internationally that provide open source mapping and data services: <a href="http://datadrivendetroit.org/">Data Driven Detroit</a>, <a href="http://datakind.org/">DataKind</a>, <a href="http://www.openstreetmap.org/">Open Street Map</a>, among others. There are also many technical solutions to any problem of creating maps, but for those (like me) immersed in technical solutions, it is easy to forget the time and energy it takes to reach the baseline for these tools (for example, <a href="http://postgis.net/">PostGIS</a>).<sup id='fnref:1'><a href='#fn:1' rel='footnote'>1</a></sup></p>

<p>However, some (not all) of these services are prohibitively expensive, some require a more intermediate level of technical skill for productive use than her organization could spare or hire, and most are dependent upon data collections already existing. Thus, her question. She and others were spending a lot of time copying and pasting that didn&#8217;t need to be spent. The missing piece for a quicker finish for their project was a short &#8211; but admittedly sharp &#8211; learning curve. <em>You can write a script to do that</em>, I said, or at least thought. <em>I can write this &#8211; it&#8217;ll be fun.</em></p>

<p>Okay.</p>

<h2>first steps &amp; ethical questions</h2>

<p>The next question for me, the script-writer, then, was: is there a service that provides this information in a useful way, and do they have an API? The initial answers to this (&#8220;sort of&#8221;) are what keep me from posting code in its entirety (and leave me hoping that things will soon improve), but common sense took me a step further. Neither the Google Places API nor the Maps API on their own provided results fine-grained enough for the numbers we were looking for, knowing that, for example, there are somewhere (give or take large numbers) around 4500 places of worship in the <a href="http://en.wikipedia.org/wiki/Metro_Detroit">tri-county area</a> of Southeastern Michigan. Okay &#8211; what next?</p>

<p>Well, scraping, while useful, has the potential of stepping over TOS boundaries, not something we want &#8211; on the &#8220;client&#8221; end as an organization, nor as a developer. Nor indeed as a decent person, I guess, though I admit this judgment could depend somewhat on the TOS. (Heh.) But spending potentially-hundreds of hours copying and pasting leads to <em>some</em> (not all) of the same ends as scraping does.</p>

<p>If public data is being shared, and it&#8217;s not being used commercially<sup id='fnref:2'><a href='#fn:2' rel='footnote'>2</a></sup> , it is probably being gotten and used all the time. That&#8217;s what we use a phone book for, the ones that the city leaves on our doorsteps in Ann Arbor: say, where are the nearest couple churches? Well&#8230;</p>

<p>Whatif we access a big service provider, I thought &#8211; one that wouldn&#8217;t have to <em>worry</em> about funding bandwidth for a hit of a few seconds, with engineered breaks &#8211; what if we only hit the server once, really? Instead of leaving people to copy and paste for weeks and weeks? Say I save a sample couple html pages for testing. They just need the data faster &#8211; they need to get their project done, and they would like to make it efficient. I can write a script that automates that human effort. Maybe they&#8217;ll hit it once, or twice, thrice, not too quickly, not even within the same day, and do the rest of the analysis offline.<sup id='fnref:3'><a href='#fn:3' rel='footnote'>3</a></sup></p>

<h2>architecture basics</h2>

<p>I used the <a href="http://mechanize.rubyforge.org/">Mechanize</a> and <a href="http://nokogiri.org/">Nokogiri</a> gems for the original script: Mechanize to submit appropriate query/ies to forms, Nokogiri to parse the results displayed on webpages, and the rest is all scripting in Ruby 1.9.3. (1.9.x Ruby was important here, because of its <a href="http://www.igvita.com/2009/02/04/ruby-19-internals-ordered-hash/">ordered hashes</a>.)</p>

<p>First, initialization of a Mechanize agent:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="vg">$agent</span> <span class="o">=</span> <span class="no">Mechanize</span><span class="o">.</span><span class="n">new</span>
</span></code></pre></td></tr></table></div></figure>


<p>I used this agent in several smaller scopes and thus (yes, I can hear the scolding; I accept it) made it global for the moment.</p>

<p>Then, saving a query in a variable like so:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;community center&quot;</span> <span class="c1"># example</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then, I access the page&#8217;s forms to allow me to search for a query (in this case, the first form on the page was the relevant one for information we were interested in). For example,</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">page</span> <span class="o">=</span> <span class="vg">$agent</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;http://YOURURL.com&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">forms</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">forms</span>
</span><span class='line'><span class="n">searchform</span> <span class="o">=</span> <span class="n">forms</span><span class="o">.</span><span class="n">first</span>
</span><span class='line'><span class="n">searchform</span><span class="o">.</span><span class="n">search_terms</span> <span class="o">=</span> <span class="n">query</span>
</span><span class='line'><span class="n">results</span> <span class="o">=</span> <span class="vg">$agent</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">searchform</span><span class="p">)</span>
</span><span class='line'><span class="n">start_pg</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">uri</span> <span class="c1"># this is the page to start scraping from</span>
</span></code></pre></td></tr></table></div></figure>


<p>(Note that <strong>search_terms</strong> here is specific to the form. You&#8217;ll want to take a look at the form(s), perhaps by <code>forms.each do {|f| p f}</code> in the console, to see what the appropriate entry box is <em>named</em> on the web form you&#8217;re trying to enter a query in.</p>

<p>Also note that a form may have several fields you need to enter &#8211; say, a search term and location &#8211; and you&#8217;ll need to look for all of those fields and write a line similar to that in line 4 in the snippet above for each.)</p>

<p>Immediately after this, I throw the results into a Nokogiri document for ease of parsing HTML to pull out relevant information, since the result web pages are intended for end-user viewers and not in easy-to-parse XML or JSON like you would get from the result of an API.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">pg</span> <span class="o">=</span> <span class="ss">Nokogiri</span><span class="p">:</span><span class="ss">:HTML</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">start_pg</span><span class="p">))</span> <span class="c1"># Nokogiri document of the start page</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next, I have a <code>create_hashes(page)</code> function which expects a Nokogiri document (e.g. <code>pg</code> ) as a parameter. This function uses Nokogiri functionality to grab different pieces of information that we cared about &#8211; e.g. the name of a given place, its address, its phone number. The function handles exceptions and keeps count of the individual results gathered.<sup id='fnref:4'><a href='#fn:4' rel='footnote'>4</a></sup></p>

<p>So <code>create_hashes</code> calls another function to make sure no duplicate entries are included in any set of .csv files corresponding to the the same search. It then pulls all associated pieces of information into a Ruby hash data structure and adds that to a Ruby array of hashes, each of which corresponds to one result (one church, for example).</p>

<p>For instance, one hash might look like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="p">{</span> <span class="s2">&quot;name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;Generic Church Name&quot;</span><span class="p">,</span> <span class="s2">&quot;addr&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;1000 Streetname Dr&quot;</span><span class="p">,</span> <span class="s2">&quot;city&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;Detroit&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;MI&quot;</span><span class="p">,</span> <span class="s2">&quot;zip&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;48126&quot;</span><span class="p">,</span> <span class="s2">&quot;phone&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;555-555-5555&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><font size="-3">n.b. that is NOT a real address or phone number</font></p>

<p>I have a function <code>transform_hash(hn)</code>, where <code>hn</code> is a hash corresponding to a single result, which transforms one of the aggregated hashes into a line in a .csv file. In the case of the information I was gathering, that looked like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">def</span> <span class="nf">transform_hash</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>
</span><span class='line'>  <span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;name&#39;</span><span class="o">]</span><span class="si">}</span><span class="s2">, </span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;addr&#39;</span><span class="o">]</span><span class="si">}</span><span class="s2">, </span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;city&#39;</span><span class="o">]</span><span class="si">}</span><span class="s2">, </span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;state&#39;</span><span class="o">]</span><span class="si">}</span><span class="s2">, </span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;zip&#39;</span><span class="o">]</span><span class="si">}</span><span class="s2">, </span><span class="si">#{</span><span class="n">hn</span><span class="o">[</span><span class="s1">&#39;phone&#39;</span><span class="o">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span class='line'>  <span class="n">s</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>And I make sure that every .csv file created has the form of {date search occurred}-{location for search}-{search query}{#, if there are > 1000 unique results}, so I create a filename and open a new file with that filename for writing.</p>

<p><font size="-3">( <code>today_string()</code> is a function which creates a string of the current date in the string format I wanted: YYYY-MM-DD)</font></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">fname</span> <span class="o">=</span> <span class="n">today_string</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">+</span> <span class="n">location</span><span class="o">.</span><span class="n">gsub!</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="no">CGI</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">w</span><span class="p">)}</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">query</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="no">CGI</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">w</span><span class="p">)}</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>And finally, the script writes .csv files as appropriate, starting a new file with the header ( <code>Name, Address, City, State, Phone</code> ) each time one file reaches 990 entries (AKA 991 lines).</p>

<h2>discussion</h2>

<p>This script I typed out on first go, post the original discussion with my friend, is not exactly the code I&#8217;m most proud of from a technical perspective: programmatically, I don&#8217;t think there&#8217;s a great deal to learn for someone who is already confident with web programming in Ruby.</p>

<p>So while I’m always pleased to write good-smelling code<sup id='fnref:5'><a href='#fn:5' rel='footnote'>5</a></sup>, I honestly saw this whole scenario through rose-colored glasses because it <em>worked</em>, even though I didn’t spend a ton of hours honing it; I knew there was a possibility here so I sat down and wrote it and ran it and it helped, and that was what mattered.</p>

<p>My friend and her team needed something that worked better (in this case, “better” meant faster – and potentially more reliable) than their previous method(s) of data-gathering. I believe this solution satisfied that without crawling rudely or putting undue weight anywhere except an individual computer for a minute or so. (That is to say, it wasn&#8217;t as efficient as it really ought to be, and while it is a sustainable solution in some senses, it isn&#8217;t in others. More on this to follow.)</p>

<p>And thus I like this as an example of a good <em>use</em> of programming skill. A web app for this is in progress, but the process of hacking together a solution to this problem was valuable to me as a programmer.</p>

<p>Is there a faster way? Yes. This script brought down the team&#8217;s time expectation for the mapping project from months to days.</p>

<p>And there are lessons to be gained for your average programmer from this small project. Maybe I&#8217;d wince to ship this and maybe I wouldn&#8217;t, but in this particular case, it <em>should</em> have been shipped: it did all it needed to do for the small scope we assigned it.<sup id='fnref:6'><a href='#fn:6' rel='footnote'>6</a></sup> It also made me think seriously about what important questions are for a developer when the end-user is someone running a (simple? perhaps yes!) script on the command line, especially if that person is not necessarily <em>comfortable</em> with its use.</p>

<p>What&#8217;s the input? What&#8217;s the output? How does the API work? What&#8217;s the easiest solution, the fastest solution, the most elegant?</p>

<p>It&#8217;s easy to get caught up in jargon just answering these questions. While there is <em>usually</em> reason to have these in-depth discussions, there do exist occurrences when they are a hinderance and not a help, at least not right away. Not a lot of programmers or computer scientists work in the non-profit industry overall, especially not in jobs where technology isn&#8217;t the end goal of their particular projects. But programming skill can still be valuable there, and these kind of caveats (what questions not to ask, which performance issues (not) to worry about first&#8230;) are useful to keep in mind.</p>

<hr />

<p>Find <a href="">Part II</a> and <a href="">Part III</a></p>

<hr />

<div class="footnotes">
    <ol>
        <li id='fn:1'><p> I&#8217;ll come back to this issue in Part II
<a href='#fnref:1' rev='footnote'>↩</a></p>
</li><li id='fn:2'><p> Arguably, not even in other creative works &#8211; but this is a whole &#8216;nother issue so we&#8217;ll leave that aside for the moment
<a href='#fnref:2' rev='footnote'>↩</a></p>
</li><li id='fn:3'><p> Note: no TOS was violated in the making of this script, but it is somewhat unclear for the current incarnation, thus the pause and non-public full code.
<a href='#fnref:3' rev='footnote'>↩</a></p>
</li><li id='fn:4'><p> The count is kept specifically because the results were intended for use with ArcGIS, which, for the organization&#8217;s current tools, worked best with .CSV files of 1000 lines or fewer.
<a href='#fnref:4' rev='footnote'>↩</a></p>
</li><li id='fn:5'><p> <a href="http://en.wikipedia.org/wiki/Code_smell">On code smell</a> &#8211; thanks to David Albert for my introduction to the term
<a href='#fnref:5' rev='footnote'>↩</a></p>
</li><li id='fn:6'><p> I still welcome what code reviews are possible without posting most of the code, and/or comments or suggestions. It <em>will</em> all be open-source under the MIT license.
<a href='#fnref:6' rev='footnote'>↩</a></p>
</li>
    </ol>
</div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[10 things I learnt as default tech support]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/04/10/10-things-i-learned-as-default-tech-support/"/>
    <updated>2013-04-10T09:36:00-04:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/04/10/10-things-i-learned-as-default-tech-support</id>
    <content type="html"><![CDATA[<ol>
<li><p>Sometimes, the best system is Windows XP and Word 2000 and the mail app you hate.</p></li>
<li><p>The hardest part of unpaid tech support is learning when not to argue about (1).</p></li>
<li><p>&#8220;Being unpaid tech support&#8221; == being the youngest person in a group by 20+ years, having the most technical experience in a group re: profession or degree, or whichever turns out to be most applicable.</p></li>
<li><p>&#8220;whichever turns out to be the most applicable&#8221; in (3) is chiefly determined by your confidence in tone, if there is any question as to who&#8217;s landed the job.</p></li>
<li><p>&#8220;Why&#8221; is the easiest question to ask and the hardest one to answer.*</p></li>
<li><p>I do not like the Mac OS X mail app.</p></li>
<li><p>Even beginning to describe the differences between what you work on and what their problem is tends to be worth it approximately 15% of the time. **</p></li>
<li><p>The fact that email (and all of the cloud) is (<em>theoretically</em>) unconstrained by political boundaries is a real conceptual jump from &#8220;snail mail.&#8221; Especially if one&#8217;s professional life has been largely spent, for example, writing books on yellow notepads.</p></li>
<li><p>&#8220;I can solve this problem I&#8217;ve never seen before&#8221;, outside of work or a personal project, is often worth the frustration.***</p></li>
<li><p>You&#8217;re probably familiar with <a href="http://xkcd.com/627/">the quintessential flow chart</a> (credit Randall Monroe under a <a href="http://creativecommons.org/licenses/by-nc/2.5/">BY-NC</a> license), but there are people for whom the system this chart depends on makes sense, and there are people to whom it&#8217;s another universe. The boundary is fluid &#8211; I firmly believe this &#8211; but if you&#8217;re the resident expert (or whatever), it sure doesn&#8217;t feel that way.</p></li>
</ol>


<p><font size="-4"></p>

<p>*I have further thoughts about this, but they&#8217;re neither publicly available nor all written down</p>

<p>**I made this number up.</p>

<p>*** Not always.
</font></p>

<p><font size="-4"><strong>notes on tech support background below</strong></font></p>

<!-- more -->


<p><font size="-4">
I&#8217;ve worked in desktop support &#8211; a little over two years ago now, on a hospital IT staff. I&#8217;ve also had interactions for a long time with others working in tech support roles/full-time jobs throughout most of my life. The post itself was prompted by a vacation on which I was the youngest by 45 years: let&#8217;s guess what happened, eh? I think it was destined to be at that point, whether or not I&#8217;d actually let on that I work with computers.</p>

<p>A lot of years ago, young me, and my even younger brother, accidentally changed the resolution on the computer once and, after some struggles to return the icons to their usual, unpixelated sizes, I sent a good friend of our dad&#8217;s, a computer consultant, a detailed email about what had happened and what we&#8217;d tried, asking how to fix it. He was grateful for the detail (&#8220;you wouldn&#8217;t believe how many people don&#8217;t&#8230;&#8221;), and I was grateful in return. I don&#8217;t have the email anymore, but I remember it. And the worry over tales in the hospital IT office of doctors known to have a roar specially bottled for the tech support was assuaged by the look on the face of the nurse to whom I explained the use of a laptop trackpad.</p>

<p>This is to say, oh hey sarcasm font? (it keeps me alive! :D :D) &#8211; and I really admire for the patient people who work(ed) full- or part-time in tech support longer than I have done so far. It&#8217;s a really important job in a million circumstances, and it leads to pretty interesting revelations. (This vacation? I swear I didn&#8217;t scream, just almost. But I learnt a lot.) I obviously have only my fraction of the experiences, yes. As usual, I welcome criticism and respect trying to learn new things. As with all lists of wide and silly generalizations, exceptions exist by the thousand, I know. [I&#8217;ve spent a lot (a LOT) of time on the internet.]
</font></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[instabitly]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/03/25/instabitly/"/>
    <updated>2013-03-25T00:29:00-04:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/03/25/instabitly</id>
    <content type="html"><![CDATA[<p>Quick drive-by: <a href="https://github.com/aerenchyma/instabitly">instabitly</a>, a script I wrote recently to import saved links from <a href="http://instapaper.com">Instapaper</a> to <a href="https://bitly.com/">bit.ly</a>.</p>

<p>I did it for personal reasons &#8211; primarily because I want all this stuff stored redundantly. Obviously I haven&#8217;t solved that problem in its entirety, but there were also other reasons. Because I care about things like this. There&#8217;s a README. More, like more in the other documentation series I&#8217;ve discussed so far, will have to appear after recent projects calm down some.</p>

<p>Let me also take this opportunity to encourage you to <a href="http://www.instapaper.com/subscription">support Instapaper</a> if you can and it&#8217;s a service you like/use.</p>

<p>In my imaginary free time, I have been trying to absorb all the <a href="http://pyvideo.org/category/33/pycon-us-2013">fantastic PyCon</a> <a href="https://speakerdeck.com/pyconslides">talks</a> (I have an active imagination).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open.Michigan Analytics, the what]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/02/18/open-dot-michigan-analytics/"/>
    <updated>2013-02-18T17:05:00-05:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/02/18/open-dot-michigan-analytics</id>
    <content type="html"><![CDATA[<p>Starting in January 2013, I have been a software developer at the <a href="http://open.umich.edu">Open.Michigan Initiative</a>, which is housed within the University of Michigan Medical School. Open.Michigan (OM) promotes open licensing and open educational resources (OER), and we publish OER on our website, which is run on the <a href="https://github.com/openmichigan/OERbit">OERbit</a> framework, which in turn is based on <a href="http://drupal.org/">Drupal</a>.</p>

<p><small>(True to our goals, all the code we produce is open source, free for use and adaptation with attribution. See licenses.)</small></p>

<p>My first project is Open.Michigan Analytics &#8211; accessing, displaying, and allowing access to analytics for the resources we publish. In twelve words or fewer. Hah. I am documenting the process, including decisions and missteps as well as step-by-steps of enacted processes, especially because this includes my progress learning Drupal (I am flexible with languages, but I have most experience developing in Python, and I had never worked even semi-professionally in PHP before this project), and adaptations and contributions to a fairly new open source project, examples of which are good to have. Also, if anyone picks this up inside or outside our office, I&#8217;d like to have documentation of the development (and not just its use) around.</p>

<p>Below, I set out the original planning stages and goals for the project. Soon: the first decisions made, setup issues, and options I set out for proceeding.</p>

<!-- more -->


<hr />

<h4>01/22/2013:</h4>

<h3>Original plan, analytics project</h3>

<p><em>Our original outline of the project plan, in phases</em></p>

<h3><em>Phase I</em></h3>

<ul>
<li><strong>Goal:</strong> Display (publically) specific analytics on a given course/resource page.</li>
<li><strong>Primary audience:</strong> authors of content, and U/M leadership.</li>
<li><strong>Motivation:</strong> use analytics display as way of promoting creation of open content?

<ul>
<li>Being able to show results of open content creation and publishing to content-creators.</li>
<li>&#8220;This has been viewed this many times&#8230;&#8221;</li>
</ul>
</li>
<li><strong>Substance:</strong>

<ul>
<li>Google Analytics:

<ul>
<li>total zip downloads #</li>
<li>most downloaded material (of materials included in a course/resource on OERbit)</li>
<li>total views of course/resource</li>
<li>date last material added (?) n.b. this info included in &#8220;date last modified&#8221; field on page</li>
</ul>
</li>
<li>YouTube Analytics:

<ul>
<li>total youtube views (of videos for a given course/resource)</li>
<li>total youtube comments (#, potentially store data, depending upon TOS)</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3><em>Phase II</em></h3>

<ul>
<li><strong>Goal:</strong> flesh out display and available downloads</li>
<li><strong>Primary audience:</strong> same as <em>Phase I</em></li>
<li><strong>Motivation:</strong> same as above, with additonal possibility of content creators drilling deeper into analytics, personal results of content-creation, a better understanding for OM wrt which access points are used in what ways, which forms of material seem to be used most often, etc.</li>
</ul>


<p>[Below is significantly paraphrased from our original internal outline.]</p>

<ul>
<li><strong>Substance:</strong>

<ul>
<li><em>Display, for a given course/resource:</em>

<ul>
<li>Social media stuff</li>
<li><a href="http://deepblue.lib.umich.edu/">Deep Blue</a> downloads/views</li>
<li>Wikipedia stuff</li>
<li>number of countries accessed</li>
<li>geographic views</li>
<li>Downloads &#8211; YouTube comments (pending TOS), demographics, site demographics</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3><em>Phase III</em></h3>

<ul>
<li><strong>Goal:</strong> increased availability of and access to analytics information</li>
<li><strong>Potentially:</strong>

<ul>
<li>integrate iTunes U</li>
<li><a href="http://www.carma.umich.edu/">CARMA</a> views</li>
<li>more download options</li>
<li>further API options</li>
</ul>
</li>
<li><strong>Considerations:</strong> API updates, integration of APIs, structure of personal metadata and paradata, relation to other projects, modularity, documentation forms, UI design</li>
</ul>


<p>This plan was soon substantially revised &#8211; so exciting, right? More to come; drafts in progress. (Internal documentation + development does come first.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing, testing]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/02/18/initial-post/"/>
    <updated>2013-02-18T15:24:00-05:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/02/18/initial-post</id>
    <content type="html"><![CDATA[<p>Initial post. Content to come.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[highlight of the job]]></title>
    <link href="http://aerenchyma.github.com/blog/2012/05/02/highlight-of-the-job/"/>
    <updated>2012-05-02T14:15:00-04:00</updated>
    <id>http://aerenchyma.github.com/blog/2012/05/02/highlight-of-the-job</id>
    <content type="html"><![CDATA[<p>On May first, I reached the end of Michigan&#8217;s 2012 Winter semester, and with it the end of one of the best jobs. A student called the deadline for the final projects the &#8220;end of an era&#8221; &#8211; that&#8217;s what it felt like to us (the staff), too. (&#8220;It feels like we&#8217;re doing twenty projects!&#8221;)</p>

<p>Except that it&#8217;s more thrilling to watch people work together and seriously, rapidly and usefully learn stuff, and help each other &#8211; better to watch forty-some eureka moments than only have a few yourself.</p>

<!-- more -->


<p>I&#8217;ve been very lucky jobwise, this school year, overall. But the off-chance I got to IA for an intro programming class has lit up my life, in the worst, best, and cheesiest sense of the words. (I know, I make me feel ill, too.) Nothing, except living in a co-op, has taught me more about <i>people</i> and dealing with and reacting to others responsibly; in no job I&#8217;ve ever had, including &#8216;being a full-time student&#8217;, have I ever come home feeling like I did as many worthwhile things with my day (though certainly there are others where finishing weeks, or projects, has left me feeling as accomplished).</p>

<p>But I&#8217;ve rarely been as amazed as I often was in that lecture hall. I feel like I got to know more than fifty people this past semester, and when they left the exam, I was glad for them all, and my co-IA (who was brilliant) and I were, if anything, underestimating when we told them how proud we were and how much luck we wished for them in the future. I&#8217;ve never seen students leave an exam with so much glee and pride, and I&#8217;ve never been so sorry to see quite that many people go. (I didn&#8217;t get along with <i>that</i> many people in my high school class&#8230; that&#8217;s been a while.)</p>

<p>I&#8217;ve known for years that teaching someone else is one of the best ways to learn something thoroughly, but I didn&#8217;t know the extent to which it would change how I thought about learning, and how I thought about myself. My students have taught me good lessons over and over again. Those who struggled with concepts and kept coming back, those who leaned over to help others without giving them the answers. &#8220;Let&#8217;s break it down.&#8221; Those who played music as office hours before the final crept later and later, and laughed when I danced (just a little). &#8220;Even the GSIs are getting into it!&#8221; Well, yeah &#8211; we want to have fun too. (GSIs we weren&#8217;t, but for all intents and purposes. It was a position I&#8217;m not used to being in, but I enjoyed it.)</p>

<p>I felt heading into the job that in terms of programming, a strength of mine was explaining programming concepts, because I struggled at first and then crested the &#8211; what? the hill of difficulty? and have loved programming and building things with code ever since, but in my upper-level classes, I recognized my students&#8217; struggle on a new level and I sympathized, and I think that helped. Time-depth-wise, I was closer to their level than the rest of the staff team, by quite a lot, and though that made me nervous at the get-go, it turned out to be really valuable. I&#8217;m endlessly glad I was not the only staff member, but I work well in a team anyway (and I had an <i>awesome</i> co-IA). It is difficult to remember what it&#8217;s like <i>not</i> to know stuff (e.g. what it means to store a Python dictionary in a variable, what a for-loop does), but I found the reach backwards easier and easier as I went on. As I told the professor for whom I worked, I found myself using more than anything else things I&#8217;d learnt while playing around on my own, and things I&#8217;d learnt in the class itself, more than I used knowledge from subsequent classes.</p>

<p>Every meaningful &#8220;thank you&#8221; was ridiculously valuable to me. Every moment of sudden understanding. The look on one girl&#8217;s face as she got a web app working: &#8220;This is the best thing I&#8217;ve ever seen in my whole life; I&#8217;m so happy!&#8221; A guy&#8217;s grin as he said &#8220;Oh! We&#8217;re extracting information from the internet!&#8221; The genial frustration (&#8220;I&#8217;m back to make your life miserable, Jackie!&#8221; / &#8220;Never. What&#8217;s up?&#8221;). The glee I came to expect as I whirled on a heel to say &#8220;YES! Exactly! So what type will this be?&#8221;</p>

<p>I wanted to make a pun about dynamism and Python being dynamically typed here, but instead I&#8217;ll say that students gave me and my co-IA thank you cards they signed, and nominated us for awards that we weren&#8217;t quite eligible for (not being grad students), so the school we worked for invented a new award for us &#8211; but the students&#8217; high-fives and compliments to each other because they understood what the others were doing with APIs and Oauth tokens were the best part. &#8220;Amazing work,&#8221; they started saying to each other &#8211; and to <i>us</i> &#8211; and I couldn&#8217;t agree more. It isn&#8217;t that there were no painful or frustrating parts &#8211; holy, were there ever &#8211; but that all of them were worth it, and I learnt a lot about how I&#8217;d deal with them if that were on me. Maybe someday. I&#8217;m only sorry I can&#8217;t IA this class again.</p>

<p>Sappy as hell, OK. Who knows, that might&#8217;ve changed my career path. I guess I&#8217;ll see.</p>
]]></content>
  </entry>
  
</feed>
