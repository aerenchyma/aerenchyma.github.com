<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[everything's interesting]]></title>
  <link href="http://aerenchyma.github.com/atom.xml" rel="self"/>
  <link href="http://aerenchyma.github.com/"/>
  <updated>2013-03-25T00:56:52-04:00</updated>
  <id>http://aerenchyma.github.com/</id>
  <author>
    <name><![CDATA[Jackie Cohen]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[instabitly]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/03/25/instabitly/"/>
    <updated>2013-03-25T00:29:00-04:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/03/25/instabitly</id>
    <content type="html"><![CDATA[<p>Quick drive-by: <a href="https://github.com/aerenchyma/instabitly">instabitly</a>, a script I wrote recently to import saved links from <a href="http://instapaper.com">Instapaper</a> to <a href="https://bitly.com/">bit.ly</a>.</p>

<p>I did it for personal reasons &#8211; primarily because I want all this stuff stored redundantly. Obviously I haven&#8217;t solved that problem in its entirety, but there were also other reasons. Because I care about things like this. There&#8217;s a README. More, like more in the other documentation series I&#8217;ve discussed so far, will have to appear after recent projects calm down some.</p>

<p>Let me also take this opportunity to encourage you to <a href="http://www.instapaper.com/subscription">support Instapaper</a> if you can and it&#8217;s a service you like/use.</p>

<p>In my imaginary free time, I have been trying to absorb all the <a href="http://pyvideo.org/category/33/pycon-us-2013">fantastic PyCon</a> <a href="https://speakerdeck.com/pyconslides">talks</a> (I have an active imagination).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bridging the mapping distance: a ruby script (part 1)]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/03/08/bridging-the-mapping-distance-a-ruby-script/"/>
    <updated>2013-03-08T20:50:00-05:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/03/08/bridging-the-mapping-distance-a-ruby-script</id>
    <content type="html"><![CDATA[<h4><em>In late 2012, I was at a bar with some friends&#8230;</em></h4>

<hr />

<p>&#8230;I&#8217;ll spare you the story. The end result was that I began writing a script in order to put together a spreadsheet of locations, names, and phone numbers of certain types of sites within a certain radius. For example, places of worship (e.g. churches, mosques, temples&#8230;), within the tri-county area of Southeastern Michigan.</p>

<!--more-->


<p>Okay, so, a script to make that happen. To do what exactly? What&#8217;s the input? What&#8217;s the output? What are we searching for? What is the expected result? How many sites? What are the requirements of the files to be produced? What kind of things can we definitely process or not process? What sort of things do they need for input to ArcGIS (what they were using for mapping)?</p>

<p>The simplest answer to the latter question was <em>.CSV files</em>. Excel workbooks would work, but .CSV files are more consistent, can be opened by more programs, and are therefore better. They&#8217;re also commonly used and understood, and they look essentially like single-page Excel workbooks in Excel, which is a bonus if information will pass to people who consider themselves non-technical and work in Windows or Mac. So, cool. .CSV files of information (Name of site, St address, City, State, Zip&#8230;).</p>

<p>Some investigation came next. Would the <a href="https://developers.google.com/places/documentation/">Google Places API</a> work? That was my first thought, due to recent experience using it. No, its results weren&#8217;t nearly fine-grained enough. Was it worth a crawl through Google search results or Google maps search results to mimic what has been done by hand up to this point? After some tries, it didn&#8217;t seem to be: results were unreliable and too often missing information pieces. It was possible to fix these problems, but the overhead to make sure the information was complete did not seem to be worth the output. Was there a service that could mimic the functionality they were looking for?</p>

<p><a href="http://www.yellowpages.com">Yellowpages</a>, maybe. Its information was reliable enough to be useful and appeared to be complete enough to satisfy the granularity the organization was looking for, hoping to make maps of these sites&#8217; locations.</p>

<p>In some cases for mapping sites of given types or categories, the data was readily available. The governent provides data files, including GIS shape files, with a lot of publicly available information; beyond things like that, there are available lists from many public sources; lists of public schools and locations, for example. But it&#8217;s hard to find a list of all <em>places of worship</em> , say, because though this may be one category at a given level, on an organizational level these belong to many different categories: churches of a given denomination and Sikh Temples are usually not listed in the same public dataset, especially not throughout the tri-county area.</p>

<p>Yellowpages can find them in the same search, though, so that&#8217;s a bonus. Another problem: does Yellowpages offer a tool for download, in acceptable .csv (comma-separated values) or .tsv (tab-separated-values) format, of all the results of a certain search? At the time, the answer was no. (I&#8217;m not aware of one sponsored by Yellowpages. Feel free to correct me if I am wrong. It makes sense; there are few non-developer use cases where you&#8217;d want to download quite as many individual entries from Yellowpages as I now did.)</p>

<p>Then &#8211; and this is something I&#8217;m still training myself to do, even after years (more on this some other time, maybe) &#8211; it was time to think like a developer: <em>is there an <a href="http://en.wikipedia.org/wiki/API">API</a>?</em> <a href="http://www.yellowapi.com/">Yes, there is</a>! Does it do what I want? &#8230; Well, no. Not exactly.</p>

<p>Yet this data does not fall under <a href="http://en.wikipedia.org/wiki/Copyright">copyright</a>; it&#8217;s not creative works; it&#8217;s also publicly available information.</p>

<p>So okay, a scraper; it wouldn&#8217;t be run too many times, as the maps to be created will have a deadline and the information should only need to be gathered once, though we&#8217;d need to do testing.</p>

<p>And not just any scraper, but one that has clear documentation such that people who describe themselves as <em>non-technical</em> could use it with minimal training before a web application with an easy-to-press button could be developed.</p>

<p>In Part II will be a runthrough of the script I wrote in Ruby. More later on the choice of the Ruby language and my thought process throughout the work. See below; soon to come.</p>

<hr />

<ul>
<li><a href="http://aerenchyma.github.com/blog/2013/03/08/bridging-the-mapping-distance-a-ruby-script/">Part I: Introduction to the problem</a></li>
<li>Part II: Runthrough of the script and the process</li>
<li>Part III: Takeaways, teaching, future plans</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open.Michigan Analytics, the what]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/02/18/open-dot-michigan-analytics/"/>
    <updated>2013-02-18T17:05:00-05:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/02/18/open-dot-michigan-analytics</id>
    <content type="html"><![CDATA[<p>Starting in January 2013, I have been a part-time software developer at the <a href="http://open.umich.edu">Open.Michigan Initiative</a>, which is housed within the Enabling Technologies office of the University of Michigan Medical School Information Services department. (I also do other things within Enabling Technologies, but for the moment and this documentation, that&#8217;s not relevant.)</p>

<p>Open.Michigan (OM) promotes open licensing and open educational resources (OER), and we publish OER on our website, which is run on the <a href="https://github.com/openmichigan/OERbit">OERbit</a> framework, which in turn is based on <a href="http://drupal.org/">Drupal</a>.</p>

<p><small>(True to our goals and our message(s), all the code we produce is open source, free for use and adaptation with attribution. See licenses.)</small></p>

<p>My first project is <strong>Open.Michigan Analytics</strong> &#8211; accessing, displaying, and allowing access to analytics for the resources we publish. (Hereafter tagged as &#8221;<a href="http://aerenchyma.github.com/blog/categories/om-analytics/">om-analytics</a>.&#8221;) With encouragement from my amazing supervisors, I am documenting the process, including decisions and missteps as well as step-by-steps of enacted processes. Below, I set out the original planning stages and goals for the project. Soon: the first decisions made, setup issues, and options I set out for proceeding.</p>

<!-- more -->


<hr />

<h4>01/22/2013:</h4>

<h3>Original plan, analytics project</h3>

<p><em>Our original outline of the project plan, in phases</em></p>

<h3><em>Phase I</em></h3>

<ul>
<li><strong>Goal:</strong> Display (publically) specific analytics on a given course/resource page.</li>
<li><strong>Primary audience:</strong> authors of content, and U/M leadership.</li>
<li><strong>Motivation:</strong> use analytics display as way of promoting creation of open content?

<ul>
<li>Being able to show results of open content creation and publishing to content-creators.</li>
<li>&#8220;This has been viewed this many times&#8230;&#8221;</li>
</ul>
</li>
<li><strong>Substance:</strong>

<ul>
<li>Google Analytics:

<ul>
<li>total zip downloads #</li>
<li>most downloaded material (of materials included in a course/resource on OERbit)</li>
<li>total views of course/resource</li>
<li>date last material added (?) n.b. this info included in &#8220;date last modified&#8221; field on page</li>
</ul>
</li>
<li>YouTube Analytics:

<ul>
<li>total youtube views (of videos for a given course/resource)</li>
<li>total youtube comments (#, potentially store data, depending upon TOS)</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3><em>Phase II</em></h3>

<ul>
<li><strong>Goal:</strong> flesh out display and available downloads</li>
<li><strong>Primary audience:</strong> same as <em>Phase I</em></li>
<li><strong>Motivation:</strong> same as above, with additonal possibility of content creators drilling deeper into analytics, personal results of content-creation, a better understanding for OM wrt which access points are used in what ways, which forms of material seem to be used most often, etc.</li>
<li><strong>Substance:</strong>

<ul>
<li><em>Display, for a given course/resource:</em>

<ul>
<li>Facebook Likes</li>
<li>Tweets</li>
<li><a href="http://deepblue.lib.umich.edu/">Deep Blue</a> downloads/views</li>
<li>Wikipedia views</li>
<li>number of countries accessed (Google Analytics/YouTube)</li>
<li>views within (state of?) Michigan, vs. elsewhere</li>
<li>potentially a map of views?
  (can we create a map from a web interface?)</li>
</ul>
</li>
<li><em>Available for download:</em>

<ul>
<li>YouTube comments (pending TOS check)</li>
<li>YouTube demographics (from YT analytics)</li>
<li>Open.Michigan (course/resource landing page? overall?) demographics</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3><em>Phase III</em></h3>

<ul>
<li><strong>Goal:</strong> increased availability of and access to analytics information</li>
<li><strong>Potentially:</strong>

<ul>
<li>integrate iTunes U</li>
<li><a href="http://www.carma.umich.edu/">CARMA</a> views</li>
<li>more download options</li>
<li>?</li>
</ul>
</li>
</ul>


<p>This plan was soon substantially revised &#8211; so exciting, right? More to come; drafts in progress. (Internal documentation + development does come first&#8230;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing, testing]]></title>
    <link href="http://aerenchyma.github.com/blog/2013/02/18/initial-post/"/>
    <updated>2013-02-18T15:24:00-05:00</updated>
    <id>http://aerenchyma.github.com/blog/2013/02/18/initial-post</id>
    <content type="html"><![CDATA[<p>Initial post. Content to come.</p>
]]></content>
  </entry>
  
</feed>
